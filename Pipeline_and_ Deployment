4)pipeline 
import seaborn as sns
import pandas as pd
import numpy as np
import os
from datetime import datetime, date, timedelta
import argparse
import azureml.core
import joblib
import math
import sklearn
from azureml.core import Workspace, Dataset, Datastore
from azureml.core.compute import ComputeTarget
from azureml.core.runconfig import RunConfiguration 
from azureml.core.conda_dependencies import CondaDependencies 
from azureml.core import Environment 
from azureml.pipeline.steps import PythonScriptStep
from azureml.pipeline.core import Pipeline
from azureml.core import Experiment
from azureml.core.authentication import InteractiveLoginAuthentication

#define workspace
ws = Workspace.from_config()

compute_name = "mlops"
vm_size = "Standard_DS3_v2"
compute_target = ws.compute_targets[compute_name]

#Declaring environment
aml_config = RunConfiguration()
aml_config.target = compute_target 

USE_CURATEDUENV = True 
if USE_CURATEDUENV:
    curated_env = Environment.get(workspace = ws, name="AzureML-sklearn-0.24-ubuntu18.04-py37-cpu")
    aml_config.environment = curated_env
else:
    aml_config.environment.python.user_managed_dependencies = False
    #inside this env, setting up what all libraries will be needed
    aml_config.environment.python.conda_dependencies = CondaDependencies.create(
    #Package that will be required during the prep step
    conda_packages=['pandas','scikit-learn'],
    pip_packages=['azureml-sdk', 'azureml-dataset-runtime[fuse, pandas]', 'seaborn'],
    pin_sdk_version = False)

#Pipeline
read_data = "data_ingestion.py"
prep = "data_preprosessing.py"
model = "modeling.py"

#Script initialization
py_script_run_read = PythonScriptStep(
                script_name=read_data,
                compute_target=compute_target,
                arguments=['--input-data',"diabetes.csv"],
                runconfig = aml_config,
                allow_reuse=False)

py_script_run_prep = PythonScriptStep(
                script_name=prep,
                compute_target=compute_target,
                arguments=['--prep',"ingestion.csv"],
                runconfig = aml_config,
                allow_reuse=False)

py_script_run_model = PythonScriptStep(
                script_name=model,
                compute_target=compute_target,
                arguments=['--train',"preprocessed.csv"],
                runconfig = aml_config,
                 allow_reuse=False)
pipeline_step = [py_script_run_read, py_script_run_prep, py_script_run_model]
pipeline_1 = Pipeline(workspace=ws, steps=[pipeline_step])

#Exp1
pipeline_run = Experiment(ws, "First_run").submit(pipeline_1)
pipeline_run.wait_for_completion(show_output=True)

#Exp2
pipeline_run = Experiment(ws, "Second_run").submit(pipeline_1)
pipeline_run.wait_for_completion(show_output=True)

datastore= Datastore.get(ws, "workspaceblobstore")
datastore.download(target_path= "azureml", prefix= "model_estimator", overwrite=False)

from azureml.core.model import Model
fine_tuned_model= Model.register(model_name="rf_model_500",
model_path="./azureml/model_estimator_500.pkl",
tags={},
description= "Diabetes model",
workspace=ws)

model= Model(ws,name='rf_model_500')
print("Loaded model version",model.version)

from azureml.core import Environment

env = Environment("deploytocloudenv")
env.python.conda_dependencies.add_pip_package("joblib")
env.python.conda_dependencies.add_pip_package("numpy==1.23")
env.python.conda_dependencies.add_pip_package("scikit-learn=={}".format(sklearn.__version__))

%%writefile score3.py
import joblib
import json
import numpy as np

from azureml.core.model import Model

def init():
    global model_3
    model_3_path = Model.get_model_path(model_name='rf_model_500')
    model_3 = joblib.load(model_3_path)

def run(raw_data):
    try:
        data = json.loads(raw_data)['data']
        data = np.array(data)
        result_1 = model_3.predict(data)
        
        return {"prediction1": result_1.tolist()}
    except Exception as e:
        result = str(e)
        return result

from azureml.core.model import InferenceConfig

inference_config = InferenceConfig(entry_script="score3.py", environment=env)

from azureml.core.webservice import AciWebservice

aci_service_name = "aciservice-modelrfdiabetes"

deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)

service = Model.deploy(ws, aci_service_name, [model], inference_config, deployment_config, overwrite=True)
service.wait_for_deployment(True)

print(service.state)

datastore= Datastore.get(ws, "workspaceblobstore")
df= Dataset.Tabular.from_delimited_files(path=[(datastore,"preproessed.csv")]).to_pandas_dataframe()
df.head()

#Make Predictions Using the Deployed Service
#Convert to JSON: Take the first 5 rows of the data (for testing) and convert them to a list. 
#convert this list to a JSON string. This JSON string will be used as the input for the prediction request.
#service.run(test_sample) method sends the JSON input to the model and retrieves the predictions
import json
test_sample=json.dumps({'data':df_new[:5].tolist()})
predictions=service.run(test_sample)
predictions
